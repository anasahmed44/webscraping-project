# -*- coding: utf-8 -*-
"""webscraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yh85g-n_BYR7MncDCrEDEa2WsnkcJfnj
"""

import requests
import math
from bs4 import BeautifulSoup
import pandas as pd

# Function to return number of pages
def num_of_pages(jop_title):
  link = 'https://wuzzuf.net/search/jobs/?q=' + jop_title.replace(' ', '+') + '&a=hpb'
  response = requests.get(link) 
  soup = BeautifulSoup(response.content, 'html')
  search_tag = soup.find('span', {'class': 'css-xkh9ud'})
  num_pages = math.ceil(int(search_tag.strong.text) / 15)
  return num_pages

# function for scraping
def scrape_pages(job_title):
  number_of_pages = num_of_pages(jop_title)
  all_titles, all_links, all_locations, type_of_job= [], [], [], []
  for page in range(number_of_pages):
    link = 'https://wuzzuf.net/search/jobs/?a=hpb&q=' + jop_title.replace(' ', '%20') + '&start=' + str(page)
    response = requests.get(link)
    soup = BeautifulSoup(response.content, 'html')
    titles_links = soup.find_all('h2', {'class': 'css-m604qf'})
    titles = [tit.text for tit in titles_links]
    all_titles += titles
    links = ['https://wuzzuf.net/' + link.a['href'] for link in titles_links]
    all_links += links
    job_type = soup.find_all('div', {'class': 'css-1lh32fc'})
    job_types = [jop.text for jop in job_type]
    type_of_job += job_types
    company_location = soup.find_all('span', {'class': 'css-5wys0k'})
    locations = [location.text for location in company_location]
    all_locations += locations
  job = {}
  job['job_title'] = all_titles
  job['job_link'] = all_links
  job['job_loaction'] = all_locations
  job['job_type'] = type_of_job
  df = pd.DataFrame(job)
  return df 



  
